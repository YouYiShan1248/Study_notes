

# 机器学习概述

## 人工智能概述

### 机器学习与人工智能、深度学习

![人工智能范围](file:///D:/BaiduNetdiskDownload/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E8%8C%83%E5%9B%B4.png)

- 机器学习和人工智能，深度学习的关系
  - 机器学习是人工智能的一个实现途径
  - 深度学习是机器学习的一个方法发展而来

- 达特茅斯会议-人工智能的起点

  1956年8月，在美国汉诺斯小镇宁静的达特茅斯学院中，

  约翰·麦卡锡（John McCarthy）

  马文·闵斯基（Marvin Minsky，人工智能与认知学专家）

  克劳德·香农（Claude Shannon，信息论的创始人）

  艾伦·纽厄尔（Allen Newell，计算机科学家）

  赫伯特·西蒙（Herbert Simon，诺贝尔经济学奖得主）等科学家正聚在一起，讨论着一个完全不食人间烟火的主题：

  **用机器来模仿人类学习以及其他方面的智能。**

  会议足足开了两个月的时间，虽然大家没有达成普遍的共识，但是却为会议讨论的内容起了一个名字：

  [人工智能](https://baike.baidu.com/item/人工智能)

  因此，1956年也就成为了人工智能元年。



### 机器学习、深度学习能做些什么

**机器学习的应用场景非常多，可以说渗透到了各个行业领域当中。医疗、航空、教育、物流、电商等等领域的各种场景。**

![img](file:///D:/BaiduNetdiskDownload/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.png)

- 用在挖掘、预测领域：

  - 应用场景：店铺销量预测、量化投资、广告推荐、企业客户分类、SQL语句安全检测分类…

- 用在图像领域：

  - 应用场景：街道交通标志检测、人脸识别等等

    ![img](file:///D:/BaiduNetdiskDownload/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/images/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6.png)

- 用在自然语言处理领域：

  - 应用场景：文本分类、情感分析、自动聊天、文本检测等等

    ![img](file:///D:/BaiduNetdiskDownload/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/images/%E6%96%B0%E9%97%BB%E6%9C%BA%E5%99%A8%E4%BA%BA.png)

**当前重要的是掌握一些机器学习算法等技巧，从某个业务领域切入解决问题。**



### 人工智能阶段课程安排

![img](file:///D:/BaiduNetdiskDownload/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/images/%E8%AF%BE%E7%A8%8B%E5%AE%89%E6%8E%92.png)







## 什么是机器学习

### 定义

机器学习是从**数据**中**自动分析获得模型**，并利用**模型**对未知数据进行预测。

### 解释

![机器学习定义](file:///D:/BaiduNetdiskDownload/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9A%E4%B9%89.png)

- 我们人从大量的日常经验中归纳规律，当面临新的问题的时候，就可以利用以往总结的规律去分析现实状况，采取最佳策略。

  ![img](file:///D:/BaiduNetdiskDownload/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/images/%E7%8C%AB%E7%8B%97.png)

- 从数据（大量的猫和狗的图片）中自动分析获得模型（辨别猫和狗的规律），从而使机器拥有识别猫和狗的能力。

  ![img](file:///D:/BaiduNetdiskDownload/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/images/%E6%88%BF%E5%B1%8B%E4%BB%B7%E6%A0%BC.png)

- 从数据（房屋的各种信息）中自动分析获得模型（判断房屋价格的规律），从而使机器拥有预测房屋价格的能力。



### 数据集构成

- 结构：特征值+目标值

  ![数据集结构](file:///D:/BaiduNetdiskDownload/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/images/%E6%95%B0%E6%8D%AE%E9%9B%86%E7%BB%93%E6%9E%84.png)

> 注：
>
> - 对于每一行数据我们可以称之为**样本**。
> - 有些数据集可以没有目标值：

![img](file:///D:/BaiduNetdiskDownload/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0.png)





## 机器学习算法分类

### 学习目标

- 目标
  - 说明机器学习算法监督学习与无监督学习的区别
  - 说明监督学习中的分类、回归特点
- 应用
  - 无

### 分析1.2中的例子：

![img](file:///D:/BaiduNetdiskDownload/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/images/%E7%8C%AB%E7%8B%97.png)

- 特征值：猫/狗的图片；目标值：猫/狗-类别
  - 分类问题

![img](file:///D:/BaiduNetdiskDownload/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/images/%E6%88%BF%E5%B1%8B%E4%BB%B7%E6%A0%BC.png)

- 特征值：房屋的各个属性信息；目标值：房屋价格-连续型数据
  - 回归问题

![img](file:///D:/BaiduNetdiskDownload/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0.png)

- 特征值：人物的各个属性信息；目标值：无
  - 无监督学习





### 总结

![监督学习无监督学习区别](file:///D:/BaiduNetdiskDownload/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/images/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E5%8C%BA%E5%88%AB.png)

- 监督学习(supervised learning)（预测）
  - 定义：输入数据是由输入特征值和目标值所组成。函数的输出可以是一个连续的值(称为回归），或是输出是有限个离散值（称作分类）。
  - **分类 k-近邻算法、贝叶斯分类、决策树与随机森林、逻辑回归、神经网络**
  - **回归 线性回归、岭回归**
- 无监督学习(unsupervised learning)
  - 定义：输入数据是由输入特征值所组成。
  - **聚类 k-means**







## 机器学习开发流程

![img](file:///D:/BaiduNetdiskDownload/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BC%80%E5%8F%91%E6%B5%81%E7%A8%8B.png)

![开发流程](file:///D:/BaiduNetdiskDownload/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/images/%E5%BC%80%E5%8F%91%E6%B5%81%E7%A8%8B.png)





# 特征工程

## 数据集

- 目标
  - 知道数据集的分为训练集和测试集
  - 会使用sklearn的数据集
- 应用
  - 无



### 可用数据集

![img](file:///D:/BaiduNetdiskDownload/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/images/%E5%8F%AF%E7%94%A8%E6%95%B0%E6%8D%AE%E9%9B%86.png)

Kaggle网址：https://www.kaggle.com/datasets

UCI数据集网址： http://archive.ics.uci.edu/ml/

scikit-learn网址：[http://scikit-learn.org/stable/datasets/index.html#datasets](http://scikit-learn.org/stable/datasets/index.html)



#### Scikit-learn工具介绍

- Python语言的机器学习工具
- Scikit-learn包括许多知名的机器学习算法的实现
- Scikit-learn文档完善，容易上手，丰富的API
- 目前稳定版本0.19.1



#### 安装

```python
pip install sklearn
```

安装好之后可以通过以下命令查看是否安装成功

```python
import sklearn
```





### sklearn数据集

#### scikit-learn数据集API介绍

- sklearn.datasets
  - 加载获取流行数据集
  - datasets.load_*()
    - 获取小规模数据集，数据包含在datasets里
  - datasets.fetch_*(data_home=None)
    - 获取大规模数据集，需要从网络上下载，函数的第一个参数是data_home，表示数据集下载的目录,默认是 ~/scikit_learn_data/



#### sklearn小数据集

`sklearn.datasets.load_iris`()

加载并返回鸢尾花数据集

![img](file:///D:/BaiduNetdiskDownload/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/images/%E9%B8%A2%E5%B0%BE%E8%8A%B1%E6%95%B0%E6%8D%AE%E9%9B%86.png)



`sklearn.datasets.load_boston`()

加载并返回波士顿房价数据集

![img](file:///D:/BaiduNetdiskDownload/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/images/%E6%B3%A2%E5%A3%AB%E9%A1%BF%E6%88%BF%E4%BB%B7%E6%95%B0%E6%8D%AE%E9%9B%86.png)





#### sklearn大数据集

- sklearn.datasets.fetch_20newsgroups(data_home=None,subset=‘train’)
  - subset：'train'或者'test'，'all'，可选，选择要加载的数据集。
  - 训练集的“训练”，测试集的“测试”，两者的“全部”





#### sklearn数据集的使用

以鸢尾花数据集为例：

![img](file:///D:/BaiduNetdiskDownload/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/images/%E9%B8%A2%E5%B0%BE%E8%8A%B1%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BD%BF%E7%94%A8.png)



**sklearn数据集返回值介绍**

- load和fetch返回的数据类型datasets.base.Bunch(字典格式)
  - data：特征数据数组，是 [n_samples * n_features] 的二维 numpy.ndarray 数组
  - target：标签数组，是 n_samples 的一维 numpy.ndarray 数组
  - DESCR：数据描述
  - feature_names：特征名,新闻数据，手写数字、回归数据集没有
  - target_names：标签名



```python
from sklearn.datasets import load_iris
# 获取鸢尾花数据集
iris = load_iris()
print("鸢尾花数据集的返回值：\n", iris)
# 返回值是一个继承自字典的Bench
print("鸢尾花的特征值:\n", iris["data"])
print("鸢尾花的目标值：\n", iris.target)
print("鸢尾花特征的名字：\n", iris.feature_names)
print("鸢尾花目标值的名字：\n", iris.target_names)
print("鸢尾花的描述：\n", iris.DESCR)
```





### 数据集的划分

机器学习一般的数据集会划分为两个部分：

- 训练数据：用于训练，**构建模型**
- 测试数据：在模型检验时使用，用于**评估模型是否有效**

划分比例：

- 训练集：70% 80% 75%
- 测试集：30% 20% 30%

**数据集划分api**

- sklearn.model_selection.train_test_split(arrays, *options)
  - x 数据集的特征值
  - y 数据集的标签值
  - test_size 测试集的大小，一般为float
  - random_state 随机数种子,不同的种子会造成不同的随机采样结果。相同的种子采样结果相同。
  - return 测试集特征训练集特征值值，训练标签，测试标签(默认随机取)

```python
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split


def datasets_demo():
    """
    对鸢尾花数据集的演示
    :return: None
    """
    # 1、获取鸢尾花数据集
    iris = load_iris()
    print("鸢尾花数据集的返回值：\n", iris)
    # 返回值是一个继承自字典的Bench
    print("鸢尾花的特征值:\n", iris["data"])
    print("鸢尾花的目标值：\n", iris.target)
    print("鸢尾花特征的名字：\n", iris.feature_names)
    print("鸢尾花目标值的名字：\n", iris.target_names)
    print("鸢尾花的描述：\n", iris.DESCR)

    # 2、对鸢尾花数据集进行分割
    # 训练集的特征值x_train 测试集的特征值x_test 训练集的目标值y_train 测试集的目标值y_test
    x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=22)
    print("x_train:\n", x_train.shape)
    # 随机数种子
    x_train1, x_test1, y_train1, y_test1 = train_test_split(iris.data, iris.target, random_state=6)
    x_train2, x_test2, y_train2, y_test2 = train_test_split(iris.data, iris.target, random_state=6)
    print("如果随机数种子不一致：\n", x_train == x_train1)
    print("如果随机数种子一致：\n", x_train1 == x_train2)

    return None
```





## 特征工程介绍

- 目标
  - 了解特征工程在机器学习当中的重要性
  - 知道特征工程的分类
- 应用
  - 无

![img](file:///D:/BaiduNetdiskDownload/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/images/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E7%9A%84%E9%87%8D%E8%A6%81%E6%80%A7.png)



### 为什么需要特征工程(Feature Engineering)

> 机器学习领域的大神Andrew Ng(吴恩达)老师说“Coming up with features is difficult, time-consuming, requires expert knowledge. “Applied machine learning” is basically feature engineering. ”
>
> 注：业界广泛流传：数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。



### 什么是特征工程

特征工程是使用**专业背景知识和技巧处理数据**，**使得特征能在机器学习算法上发挥更好的作用的过程**。

> 意义：会直接影响机器学习的效果



### 特征工程的位置与数据处理的比较

![特征工程过程](file:///D:/BaiduNetdiskDownload/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/images/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E8%BF%87%E7%A8%8B.png)

- pandas:一个数据读取非常方便以及基本的处理格式的工具
- sklearn:对于特征的处理提供了强大的接口

**特征工程包含内容**

- 特征抽取
- 特征预处理
- 特征降维





## 特征抽取

将任意数据（如文本或图像）转换为可用于机器学习的数字特征

> 注：特征值化是为了计算机更好的去理解数据

- 字典特征提取(特征离散化)
- 文本特征提取
- 图像特征提取（深度学习将介绍）



**特征提取API**

```python
sklearn.feature_extraction
```





### 字典特征提取

**作用：对字典数据进行特征值化**

- sklearn.feature_extraction.DictVectorizer(sparse=True,…)
  - DictVectorizer.fit_transform(X) X:字典或者包含字典的迭代器返回值：返回sparse矩阵
  - DictVectorizer.inverse_transform(X) X:array数组或者sparse矩阵 返回值:转换之前数据格式
  - DictVectorizer.get_feature_names() 返回类别名称





**应用**

我们对以下数据进行特征提取

```python
[{'city': '北京','temperature':100}
{'city': '上海','temperature':60}
{'city': '深圳','temperature':30}]
```

![dictvec结果](file:///D:/BaiduNetdiskDownload/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/images/dictvec%E7%BB%93%E6%9E%9C.png)





**具体流程**

- 实例化类DictVectorizer
- 调用fit_transform方法输入数据并转换（注意返回格式）

```python
from sklearn.feature_extraction import DictVectorizer

def dict_demo():
    """
    对字典类型的数据进行特征抽取
    :return: None
    """
    data = [{'city': '北京','temperature':100}, {'city': '上海','temperature':60}, {'city': '深圳','temperature':30}]
    # 1、实例化一个转换器类
    transfer = DictVectorizer(sparse=False)
    # 2、调用fit_transform
    data = transfer.fit_transform(data)
    print("返回的结果:\n", data)
    # 打印特征名字
    print("特征名字：\n", transfer.get_feature_names())

    return None
```

注意观察没有加上sparse=False参数的结果

> 这个是稀疏矩阵，节省内存的

```python
返回的结果:
   (0, 1)    1.0
  (0, 3)    100.0
  (1, 0)    1.0
  (1, 3)    60.0
  (2, 2)    1.0
  (2, 3)    30.0
特征名字：
 ['city=上海', 'city=北京', 'city=深圳', 'temperature']
```

这个结果并不是我们想要看到的，所以加上参数，得到想要的结果：

```python
返回的结果:
 [[   0.    1.    0.  100.]
 [   1.    0.    0.   60.]
 [   0.    0.    1.   30.]]
特征名字：
 ['city=上海', 'city=北京', 'city=深圳', 'temperature']
```

之前在学习pandas中的离散化的时候，也实现了类似的效果。

我们把这个处理数据的技巧叫做”one-hot“编码：

![onehot](file:///D:/BaiduNetdiskDownload/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/images/onehot.png)

转化为：

![onehot1](file:///D:/BaiduNetdiskDownload/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/images/onehot1.png)

**总结**

对于特征当中存在类别信息的我们都会做one-hot编码处理

> 这种编码方式是为了让各个类别没有额外的数字意义

